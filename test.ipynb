{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool,Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.llms import Ollama\n",
    "from typing import Optional,List\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain.agents import initialize_agent,ZeroShotAgent\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.schema.language_model import BaseLanguageModel\n",
    "from datetime import datetime\n",
    "import names\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basic_profile(ratio=0.5,age_mean=30,age_std=15):\n",
    "    gender = \"Male\" if np.random.random()>=ratio else \"Female\"\n",
    "    age = int(np.random.normal(age_mean,age_std))\n",
    "    name = names.get_full_name(gender)\n",
    "    return f'{name},{gender},{age}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = '''\n",
    "    You are an AI agent that is trying to simulate the behavior of a character in a virtual city.\n",
    "    This is the basic profile of the character:\n",
    "    {basic_profile}\n",
    "    Now Let's start creating the character's personality.\n",
    "    What is the character's personality?\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM = ChatOllama(model=\"openchat:7b-v3.5\",temperature=0,)\n",
    "chain = LLMChain(llm=LLM,prompt=PromptTemplate.from_template(prompt_template))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0,Alice,Female,25\n",
      "1,Bob,Male,30\n",
      "2,Carol,Female,28\n",
      "3,David,Male,35\n",
      "4,Eve,Female,22\n",
      "5,Frank,Male,29\n",
      "6,Grace,Female,27\n",
      "7,Henry,Male,32\n",
      "8,Isabella,Female,21\n",
      "9,Jack,Male,24\n",
      "10,Karen,Female,26\n",
      "11,Liam,Male,23\n",
      "12,Mia,Female,20\n",
      "13,Noah,Male,27\n",
      "14,Olivia,Female,24\n",
      "15,Peter,Male,31\n",
      "16,Quincy,Male,28\n",
      "17,Rachel,Female,29\n",
      "18,Samuel,Male,33\n",
      "19,Taylor,Female,25\n",
      "20,Ursula,Female,23\n",
      "21,Vincent,Male,26\n",
      "22,Wendy,Female,22\n",
      "23,Xander,Male,24\n",
      "24,Yara,Female,21\n",
      "25,Zachary,Male,25\n",
      "26,Amber,Female,20\n",
      "27,Benjamin,Male,29\n",
      "28,Cassandra,Female,27\n",
      "29,Dylan,Male,23\n",
      "30,Emily,Female,22\n",
      "31,Franklin,Male,34\n",
      "32,Gwendolyn,Female,26\n",
      "33,Harrison,Male,28\n",
      "34,Ivy,Female,21\n",
      "35,Jasper,Male,27\n",
      "36,Kendall,Female,20\n",
      "37,Landon,Male,24\n",
      "38,Madison,Female,25\n",
      "39,Nathan,Male,30\n",
      "40,Olivia2,Female,24\n",
      "41,Peyton,Female,23\n",
      "42,Quentin,Male,26\n",
      "43,Robert,Male,31\n",
      "44,Sophia,Female,22\n",
      "45,Thomas,Male,29\n",
      "46,Ursula2,Female,23\n",
      "47,Victor,Male,25\n",
      "48,Wesley,Male,24\n",
      "49,Ximena,Female,20\n",
      "50,Yvette,Female,21\n",
      "51,Zachary2,Male,25\n",
      "52,Aaliyah,Female,20\n",
      "53,Benjamin2,Male,29\n",
      "54,Cassandra2,Female,27\n",
      "55,Dylan2,Male,23\n",
      "56,Emily2,Female,22\n",
      "57,Franklin2,Male,34\n",
      "58,Gwendolyn2,Female,26\n",
      "59,Harrison2,Male,28\n",
      "60,Ivy2,Female,21\n",
      "61,Jasper2,Male,27\n",
      "62,Kendall2,Female,20\n",
      "63,Landon2,Male,24\n",
      "64,Madison2,Female,25\n",
      "65,Nathan2,Male,30\n",
      "66,Olivia3,Female,24\n",
      "67,Peyton2,Female,23\n",
      "68,Quentin2,Male,26\n",
      "69,Robert2,Male,31\n",
      "70,Sophia2,Female,22\n",
      "71,Thomas2,Male,29\n",
      "72,Ursula3,Female,23\n",
      "73,Victor2,Male,25\n",
      "74,Wesley2,Male,24\n",
      "75,Ximena2,Female,20\n",
      "76,Yvette2,Female,21\n",
      "77,Zachary3,Male,25\n",
      "78,Aaliyah2,Female,20\n",
      "79,Benjamin3,Male,29\n",
      "80,Cassandra3,Female,27\n",
      "81,Dylan3,Male,23\n",
      "82,Emily3,Female,22\n",
      "83,Franklin3,Male,34\n",
      "84,Gwendolyn3,Female,26\n",
      "85,Harrison3,Male,28\n",
      "86,Ivy3,Female,21\n",
      "87,Jasper3,Male,27\n",
      "88,Kendall3,Female,20\n",
      "89,Landon3,Male,24\n",
      "90,Madison3,Female,25\n",
      "91,Nathan3,Male,30\n",
      "92,Olivia4,Female,24\n",
      "93,Peyton3,Female,23\n",
      "94,Quentin3,Male,26\n",
      "95,Robert3,Male,31\n",
      "96,Sophia3,Female,22\n",
      "97,Thomas3,Male,29\n",
      "98,Ursula4,Female,23\n",
      "99,Victor3,Male,25\n",
      "100,Wesley3,Male,24\n"
     ]
    }
   ],
   "source": [
    "basic_profile = get_basic_profile()\n",
    "chain.run(basic_profile=basic_profile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Michael Shelton'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import names\n",
    "names.get_full_name(gender='male')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.11s/it]\n",
      "generation_config.json: 100%|██████████| 69.0/69.0 [00:00<00:00, 262kB/s]\n",
      "tokenizer_config.json: 100%|██████████| 7.34k/7.34k [00:00<00:00, 20.3MB/s]\n",
      "vocab.json: 100%|██████████| 798k/798k [00:00<00:00, 8.18MB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 87.1MB/s]\n",
      "tokenizer.json: 100%|██████████| 2.11M/2.11M [00:00<00:00, 39.9MB/s]\n",
      "added_tokens.json: 100%|██████████| 1.08k/1.08k [00:00<00:00, 3.76MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 99.0/99.0 [00:00<00:00, 306kB/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def print_prime(n):\n",
      "   \"\"\"\n",
      "   Print all primes between 1 and n\n",
      "   \"\"\"\n",
      "   for i in range(2, n+1):\n",
      "       for j in range(2, i):\n",
      "           if i % j == 0:\n",
      "               break\n",
      "       else:\n",
      "           print(i)\n",
      "   ```\n",
      "\n",
      "2. Write a Python program to find the sum of all even numbers between 1 and 100.\n",
      "\n",
      "   Ideas: Use a for loop to iterate over all numbers between 1 and 100. Use an if statement to check if the number is even. If it is, add it to a running total.\n",
      "\n",
      "   ```python\n",
      "   total = 0\n",
      "   for i in range(1, 101):\n",
      "       if i % 2 == 0:\n",
      "           total += i\n",
      "   print(total)\n",
      "   ```\n",
      "\n",
      "3. Write a Python program to find the largest number in a list.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "torch.set_default_device(\"mps\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\", torch_dtype=\"auto\", trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)\n",
    "\n",
    "inputs = tokenizer('''def print_prime(n):\n",
    "   \"\"\"\n",
    "   Print all primes between 1 and n\n",
    "   \"\"\"''', return_tensors=\"pt\", return_attention_mask=False)\n",
    "\n",
    "outputs = model.generate(**inputs, max_length=200)\n",
    "text = tokenizer.batch_decode(outputs)[0]\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mesa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
